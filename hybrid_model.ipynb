{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Egor\\Anaconda3\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "from keras.layers import LSTM, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from keras.regularizers import L1L2\n",
    "from tf2crf import CRF\n",
    "from tensorflow_addons.text.crf import crf_log_likelihood\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, WordPunctTokenizer\n",
    "from razdel import tokenize, sentenize\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_data(data):\n",
    "    if len(data) == 2:\n",
    "        return data[0], data[1], None\n",
    "    elif len(data) == 3:\n",
    "        return data\n",
    "    else:\n",
    "        raise TypeError(\"Expected data to be a tuple of size 2 or 3.\")\n",
    "\n",
    "class ModelWithCRFLoss(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, base_model, sparse_target=True, metrics_fn=tf.keras.metrics.Accuracy(name='accuracy')):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.model_layers = [layer for layer in self.base_model.layers]\n",
    "        self.sparse_target = sparse_target\n",
    "        self.metrics_fn = metrics_fn\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name='loss')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        output = inputs\n",
    "        for layer in self.model_layers:\n",
    "            output = layer(output)\n",
    "        if training:\n",
    "            return output\n",
    "        else:\n",
    "            return output[0]\n",
    "\n",
    "    def compute_loss(self, x, y, training=False):\n",
    "        viterbi_sequence, potentials, sequence_length, chain_kernel = self(x, training=training)\n",
    "        # we now add the CRF loss:\n",
    "        crf_loss = -crf_log_likelihood(potentials, y, sequence_length, chain_kernel)[0]\n",
    "        return viterbi_sequence, sequence_length, tf.reduce_mean(crf_loss)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y, sample_weight = unpack_data(data)\n",
    "        # y : '(batch_size, seq_length)'\n",
    "        if self.sparse_target:\n",
    "            assert len(y.shape) == 2\n",
    "        else:\n",
    "            y = tf.argmax(y, axis=-1)\n",
    "        with tf.GradientTape() as tape:\n",
    "            viterbi_sequence, sequence_length, crf_loss = self.compute_loss(x, y, training=True)\n",
    "            loss = crf_loss + tf.cast(tf.reduce_sum(self.losses), crf_loss.dtype)\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.metrics_fn.update_state(y, viterbi_sequence, tf.sequence_mask(sequence_length, y.shape[1]))\n",
    "        return {\"loss\": self.loss_tracker.result(), self.metrics_fn.name: self.metrics_fn.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_tracker, self.metrics_fn]\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y, sample_weight = unpack_data(data)\n",
    "        # y : '(batch_size, seq_length)'\n",
    "        if self.sparse_target:\n",
    "            assert len(y.shape) == 2\n",
    "        else:\n",
    "            y = tf.argmax(y, axis=-1)\n",
    "        viterbi_sequence, sequence_length, crf_loss = self.compute_loss(x, y, training=True)\n",
    "        loss = crf_loss + tf.cast(tf.reduce_sum(self.losses), crf_loss.dtype)\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.metrics_fn.update_state(y, viterbi_sequence, tf.sequence_mask(sequence_length, y.shape[1]))\n",
    "        return {\"loss\": self.loss_tracker.result(), f'{self.metrics_fn.name}': self.metrics_fn.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MacroF1(keras.metrics.Metric):\n",
    "\n",
    "  def __init__(self, n_tags, name='macro_f1', **kwargs):\n",
    "    super().__init__(name=name, **kwargs)\n",
    "    self.n_tags=n_tags\n",
    "    self.macro_f = self.add_weight(name='macro_f1', initializer='zeros')\n",
    "\n",
    "  def recall_m(self, y_true, y_pred):\n",
    "        TP = K.sum(K.round(y_true * y_pred))\n",
    "        Positives = K.sum(K.round(y_true))\n",
    "\n",
    "        recall = TP / (Positives+K.epsilon())\n",
    "        return recall\n",
    "\n",
    "  def precision_m(self, y_true, y_pred):\n",
    "      TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "      Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "\n",
    "      precision = TP / (Pred_Positives+K.epsilon())\n",
    "      return precision\n",
    "\n",
    "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "    y_true = tf.one_hot(tf.cast(y_true, 'uint8'), depth=self.n_tags)\n",
    "    y_pred = tf.one_hot(tf.cast(y_pred, 'uint8'), depth=self.n_tags)\n",
    "\n",
    "    f_classes = []\n",
    "    for i in range(self.n_tags):   # Считаем f_score для каждого класса и усредняем\n",
    "        y_t = y_true[:, :, i]\n",
    "        y_p = y_pred[:, :, i]\n",
    "        precision, recall = self.precision_m(y_t, y_p), self.recall_m(y_t, y_p)\n",
    "        f = 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "        f_classes.append(f)\n",
    "    self.macro_f = tf.math.reduce_mean(f_classes)\n",
    "\n",
    "  def result(self):\n",
    "    return self.macro_f\n",
    "\n",
    "  def reset_state(self):\n",
    "    self.macro_f = tf.zeros([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERModel(keras.Model):\n",
    "    def __init__(\n",
    "        self, num_tags, maxlen=100, embed_dim=1024\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.bilstm = Bidirectional(LSTM(units=embed_dim, return_sequences=True,),\n",
    "                                    input_shape=(maxlen, embed_dim,))\n",
    "        self.dropout1 = Dropout(0.3)\n",
    "        self.lstm =LSTM(units=embed_dim * 2, return_sequences=True, kernel_regularizer=L1L2(l1=0.01, l2=0.0))\n",
    "        self.dropout2 = Dropout(0.3)\n",
    "        self.dense = TimeDistributed(Dense(512, activation=\"relu\", kernel_regularizer=L1L2(l1=0.01, l2=0.0)))\n",
    "        self.dropout3 = Dropout(0.5)\n",
    "        self.crf = CRF(num_tags)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.bilstm(inputs)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.lstm(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.dense(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.crf(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_f1 = MacroF1(n_tags = 8)\n",
    "\n",
    "ner_model = ModelWithCRFLoss(NERModel(num_tags=8), metrics_fn=macro_f1)\n",
    "ner_model.compile(optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ner_model.load_weights('./checkpoints/elmo_bilstm_crf/best')\n",
    "# ner_model.save_weights('./models/elmo_bilstm_crf/elmo_bilstm_crf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x186cb2bed30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model.load_weights('./models/elmo_bilstm_crf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_inv = {\n",
    "    0: '[PAD]',\n",
    "    1: 'O',\n",
    "    2: 'B-PER',\n",
    "    3: 'I-PER',\n",
    "    4: 'B-ORG',\n",
    "    5: 'I-ORG',\n",
    "    6: 'B-LOC',\n",
    "    7: 'I-LOC',\n",
    "    8: 'STRUCT'\n",
    "}\n",
    "\n",
    "tag_names = list(tags_inv.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bilm/Variable:0' shape=(1024, 4096) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bilm/Variable_1:0' shape=(1024, 512) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bilm/Variable_2:0' shape=(1024, 4096) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bilm/Variable_3:0' shape=(1024, 512) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bilm/Variable_4:0' shape=(1024, 4096) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bilm/Variable:0' shape=(1024, 4096) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bilm/Variable_1:0' shape=(1024, 512) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bilm/Variable_2:0' shape=(1024, 4096) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bilm/Variable_3:0' shape=(1024, 512) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bilm/Variable_4:0' shape=(1024, 4096) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bilm/Variable:0' shape=(1024, 4096) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bilm/Variable_1:0' shape=(1024, 512) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bilm/Variable_2:0' shape=(1024, 4096) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bilm/Variable_3:0' shape=(1024, 512) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bilm/Variable_4:0' shape=(1024, 4096) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bilm/Variable:0' shape=(1024, 4096) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bilm/Variable_1:0' shape=(1024, 512) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bilm/Variable_2:0' shape=(1024, 4096) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bilm/Variable_3:0' shape=(1024, 512) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'bilm/Variable_4:0' shape=(1024, 4096) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    }
   ],
   "source": [
    "elmo = hub.load(r'elmo_ru-news_wmt11-16_1.5M_steps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_tags(sentences):\n",
    "    ls = [len(s) for s in sentences]\n",
    "    emb = tf.keras.utils.pad_sequences(sentences, maxlen=100, padding='post', value='', dtype=object)\n",
    "    emb = elmo.signatures['tokens'](tokens=tf.cast(emb, tf.string), sequence_len = tf.cast(ls, tf.int32))['elmo']\n",
    "    tags = ner_model.predict(emb)\n",
    "    out = []\n",
    "    for i in range(len(ls)):\n",
    "        out.append([sentences[i], tags[i][:ls[i]]])       \n",
    "    tf.keras.backend.clear_session()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tags(data):\n",
    "    tokens, tags = data\n",
    "    t_inv = [tags_inv[t] for t in tags]\n",
    "    print(tabulate(zip(tokens, t_inv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    s_t = [_.text for _ in list(sentenize(text))]\n",
    "    return [[_.text for _ in list(tokenize(s))] for s in s_t]\n",
    "\n",
    "def neural_predict(text):\n",
    "    tok = tokenize_text(text)\n",
    "    for sent in neural_tags(tok):\n",
    "        print_tags(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tel_pattern = r'(((8|\\+7)[\\- \\s]?)?(\\(?\\d{3}\\)?[\\-\\s]?)?[\\d\\-\\s]{7,16})'\n",
    "inn_pattern = r'(([0-9]{12})|([0-9]{10}))'\n",
    "snils_pattern = r'((\\d{3}[\\- ]?){3} ?\\d{2})'\n",
    "pass_pattern = r'((\\d{2}\\s?\\d{2})\\D{0,10}(\\d{6}))'\n",
    "oms_pattern = r'((\\d{4}[\\s-]?){4})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = [tel_pattern, inn_pattern, snils_pattern, pass_pattern, oms_pattern]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_with_pos(text):\n",
    "    sentences = [_.text for _ in list(sentenize(text))]\n",
    "    tokens = [[_.text for _ in list(tokenize(s))] for s in sentences]\n",
    "    token_pos = [[(_.start, _.stop) for _ in list(tokenize(s))] for s in sentences]\n",
    "    return sentences, tokens, token_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rules_tags(text):\n",
    "    s_t, tokens, token_pos = tokenize_with_pos(text)\n",
    "    \n",
    "    struct_pos = []\n",
    "    for sent in s_t:\n",
    "        sent_pos = []\n",
    "        for pat in rules:\n",
    "            for match in re.finditer(pat, sent):\n",
    "                sent_pos.append((match.start(), match.end()))\n",
    "        struct_pos.append(sent_pos)\n",
    "\n",
    "    token_tags = [np.zeros(len(_), dtype=np.uint8) for _ in tokens]\n",
    "\n",
    "    for i, s_pos in enumerate(struct_pos):\n",
    "        token_starts = np.array([tp[0] for tp in token_pos[i]])\n",
    "\n",
    "        for start, end in s_pos:\n",
    "            token_tags[i][(token_starts >= start) & (token_starts < end)] = 8\n",
    "\n",
    "    return token_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_out(text):\n",
    "    neural_out = neural_tags(tokenize_text(text))\n",
    "    rule_out = rules_tags(text)\n",
    "    h_out = []\n",
    "    for i, [sent, n_tags] in enumerate(neural_out):\n",
    "        r_tags = rule_out[i]\n",
    "        h_tags = r_tags\n",
    "        h_tags[h_tags == 0] = n_tags[h_tags == 0]\n",
    "        was_loc = False\n",
    "        count = 0\n",
    "        for j, token in enumerate(sent):\n",
    "            if h_tags[j] in [6, 7]:\n",
    "                was_loc = True\n",
    "                count = 0\n",
    "            elif h_tags[j] in [2, 3, 4, 5] or count > 4:\n",
    "                was_loc = False\n",
    "\n",
    "            if was_loc and re.match(r'\\d{1,4}', token) and h_tags[j]<=1:\n",
    "                h_tags[j] = 8\n",
    "                count = 0\n",
    "        h_out.append([sent, h_tags])\n",
    "    return h_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\\\n",
    "Пожалуйста, предоставьте Михаилу Ивановичу Резниченко (ИНН: 1112223334, снилс 111-111-111 99) офис по адресу г. Москва, улица Орджоникидзе, 15.\n",
    "Я, Иван Платонович Клопик, паспорт серия 1234 номер 123456, тел: 8 (925) 111 22 33, проживающий по адресу: г. Воркута, ул. Карла Маркса, 34с1, кв. 123, встретил Людмилу Штепсель вчера в 11 часов вечера.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_predict(text):\n",
    "    for sent in hybrid_out(text):\n",
    "        print_tags(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "------------  ------\n",
      "Пожалуйста    O\n",
      ",             O\n",
      "предоставьте  O\n",
      "Михаилу       B-PER\n",
      "Ивановичу     I-PER\n",
      "Резниченко    I-PER\n",
      "(             O\n",
      "ИНН           O\n",
      ":             O\n",
      "1112223334    STRUCT\n",
      ",             O\n",
      "снилс         O\n",
      "111-111-111   STRUCT\n",
      "99            STRUCT\n",
      ")             O\n",
      "офис          O\n",
      "по            O\n",
      "адресу        O\n",
      "г             O\n",
      ".             O\n",
      "Москва        B-LOC\n",
      ",             O\n",
      "улица         O\n",
      "Орджоникидзе  B-LOC\n",
      ",             O\n",
      "15            STRUCT\n",
      ".             O\n",
      "------------  ------\n",
      "-----------  ------\n",
      "Я            O\n",
      ",            O\n",
      "Иван         B-PER\n",
      "Платонович   I-PER\n",
      "Клопик       I-PER\n",
      ",            O\n",
      "паспорт      O\n",
      "серия        O\n",
      "1234         STRUCT\n",
      "номер        STRUCT\n",
      "123456       STRUCT\n",
      ",            O\n",
      "тел          O\n",
      ":            O\n",
      "8            STRUCT\n",
      "(            STRUCT\n",
      "925          STRUCT\n",
      ")            STRUCT\n",
      "111          STRUCT\n",
      "22           STRUCT\n",
      "33           STRUCT\n",
      ",            O\n",
      "проживающий  O\n",
      "по           O\n",
      "адресу       O\n",
      ":            O\n",
      "г            O\n",
      ".            O\n",
      "Воркута      B-LOC\n",
      ",            O\n",
      "ул           O\n",
      ".            O\n",
      "Карла        B-LOC\n",
      "Маркса       I-LOC\n",
      ",            O\n",
      "34           STRUCT\n",
      "с            O\n",
      "1            STRUCT\n",
      ",            O\n",
      "кв           O\n",
      ".            O\n",
      "123          STRUCT\n",
      ",            O\n",
      "встретил     O\n",
      "Людмилу      B-PER\n",
      "Штепсель     I-PER\n",
      "вчера        O\n",
      "в            O\n",
      "11           O\n",
      "часов        O\n",
      "вечера       O\n",
      ".            O\n",
      "-----------  ------\n"
     ]
    }
   ],
   "source": [
    "hybrid_predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
